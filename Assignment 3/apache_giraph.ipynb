{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!apt-get update && apt-get install -y openjdk-11 maven wget unzip\n",
    "\n",
    "# Set environment variables\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'\n",
    "os.environ['HADOOP_HOME'] = '/content/hadoop'\n",
    "os.environ['PATH'] += ':' + os.environ['HADOOP_HOME'] + '/bin:' + os.environ['HADOOP_HOME'] + '/sbin'\n",
    "\n",
    "# Download and unpack Hadoop\n",
    "!wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.5/hadoop-3.3.5.tar.gz\n",
    "!tar -xvf hadoop-3.3.5.tar.gz\n",
    "!mv hadoop-3.3.5 hadoop\n",
    "\n",
    "# Download and unpack Giraph\n",
    "!wget https://archive.apache.org/dist/giraph/giraph-1.3.0/giraph-1.3.0-for-hadoop-3-jar-with-dependencies.jar\n",
    "# (Alternatively clone source and build with maven)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure minimal hadoop settings for local mode\n",
    "!cat <<EOF > $HADOOP_HOME/etc/hadoop/core-site.xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.defaultFS</name>\n",
    "    <value>hdfs://localhost:9000</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "EOF\n",
    "\n",
    "!cat <<EOF > $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>1</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "EOF\n",
    "\n",
    "# Format namenode and start dfs & yarn\n",
    "!$HADOOP_HOME/bin/hdfs namenode -format\n",
    "!$HADOOP_HOME/sbin/start-dfs.sh\n",
    "!$HADOOP_HOME/sbin/start-yarn.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget https://snap.stanford.edu/data/wiki-Vote.txt.gz\n",
    "!gunzip wiki-Vote.txt.gz\n",
    "\n",
    "# Convert to adjacency list format for Giraph: each line “vertex_id neighbour1:0 neighbour2:0 …”\n",
    "# Using python preprocessing\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "adj = defaultdict(list)\n",
    "with open('wiki-Vote.txt','r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        src, dst = line.strip().split()\n",
    "        adj[src].append(dst)\n",
    "\n",
    "with open('wikiVote_adj.txt','w') as f_out:\n",
    "    for v, nbrs in adj.items():\n",
    "        line = v + ' ' + ' '.join([nbr+':0' for nbr in nbrs])\n",
    "        f_out.write(line + '\\n')\n",
    "\n",
    "# Upload that to HDFS\n",
    "!$HADOOP_HOME/bin/hdfs dfs -mkdir /input\n",
    "!$HADOOP_HOME/bin/hdfs dfs -put wikiVote_adj.txt /input/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/apache/giraph.git\n",
    "!cd giraph && mvn clean install -DskipTests\n",
    "\n",
    "# For simplicity, assume we’ll use pre-built jar:\n",
    "GIRAPH_JAR = '/content/giraph-1.3.0-for-hadoop-3-jar-with-dependencies.jar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Weakly Connected Components job\n",
    "!hadoop jar {GIRAPH_JAR} org.apache.giraph.GiraphRunner \\\n",
    "  org.apache.giraph.examples.WCCComputation \\\n",
    "  -vif org.apache.giraph.io.formats.LongLongNullTextInputFormat \\\n",
    "  -vip /input/wikiVote_adj.txt \\\n",
    "  -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \\\n",
    "  -op /output/WCC -w 1\n",
    "\n",
    "# Capture execution time (you may note output time from log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4758319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two‐phase SCC (implement your class) \n",
    "!hadoop jar {GIRAPH_JAR} your.package.SCCComputation \\\n",
    "  -vif … -vip /input/wikiVote_adj.txt -vof … -op /output/SCC -w 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ab1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run triangle counting – implement your class\n",
    "!hadoop jar {GIRAPH_JAR} your.package.TriangleCountComputation \\\n",
    "  -vif … -vip /input/wikiVote_adj.txt -vof … -op /output/Triangles -w 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c20a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run clustering coefficient – implement your class\n",
    "!hadoop jar {GIRAPH_JAR} your.package.ClusteringCoefficientComputation \\\n",
    "  -vif … -vip /input/wikiVote_adj.txt -vof … -op /output/ClusteringCoeff -w 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BFS sampling based diameter job – implement your class\n",
    "!hadoop jar {GIRAPH_JAR} your.package.DiameterComputation \\\n",
    "  -vif … -vip /input/wikiVote_adj.txt -vof … -op /output/Diameter -w 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
